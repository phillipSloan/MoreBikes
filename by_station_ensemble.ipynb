{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d250270",
   "metadata": {},
   "source": [
    "# Notebook for subtask-A of phase one\n",
    "\n",
    "## Fitting a model to each individual station\n",
    "\n",
    "Here we construct an ensemble, with the use case of predicting for new stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffe13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5cfaa",
   "metadata": {},
   "source": [
    "# Define some functions\n",
    "\n",
    "- replace_nan fills NaN values with column means. We don't use it but it was useful for exploratory analysis\n",
    "- show_nans is also for exploration\n",
    "- convert_weekdays moves weekday strings into integers from one to seven\n",
    "- score_abs_error takes a model with SKLEARN syntax and used it to predict the number of bikes based on input data, then return the mean absolute error. round_ specifies whether output should be rounded to integers.\n",
    "- reasonable_predictions is a bit redundant, taking a model and data and predicting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(df):\n",
    "    # get a list of all the columns containing NaN\n",
    "    nan_cols = df[df.columns[df.isnull().any()]].columns\n",
    "    nan_cols = nan_cols.drop('bikes')\n",
    "    # compute and fill each NaN with the columns mean\n",
    "    df[nan_cols] = df[nan_cols].fillna(value=df[nan_cols].mean())\n",
    "\n",
    "    \n",
    "def show_nans(df):\n",
    "    print(np.unique(df['station']))\n",
    "    print(df.shape[0] - df.dropna().shape[0])\n",
    "#     print(df[df.columns[df.isnull().any()]].columns)\n",
    "    print(df.isnull().any())\n",
    "    print()\n",
    "    \n",
    "\n",
    "# converting weekdays into integers [1-7]\n",
    "def convert_weekdays(df):\n",
    "    df = df.replace(\n",
    "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    [1, 2, 3, 4, 5, 6, 7])\n",
    "    return df\n",
    "    \n",
    "def score_abs_error(model, data, num_docks, round_ = False):\n",
    "    if round_ == True:\n",
    "        y_pred = np.around(  model.predict(data.iloc[:,:-1].to_numpy()))# * num_docks  )\n",
    "    else:\n",
    "        y_pred = model.predict(data.iloc[:,:-1].to_numpy())# * num_docks\n",
    "    y_gold = data[\"bikes\"].to_numpy()# * num_docks\n",
    "    \n",
    "    return mean_absolute_error(y_gold, y_pred)\n",
    "\n",
    "def reasonable_predictions(model, data):\n",
    "    y_pred = model.predict(data.to_numpy())\n",
    "    \n",
    "    y_pred = np.around(y_pred)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50972766",
   "metadata": {},
   "source": [
    "The next cell has functions to remove unwanted features, add our new isOff feature. \n",
    "\n",
    "It reads all the training files and builds collections of training sets, validation sets, and scalers for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7082700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations kept as holdout: [255 229]\n",
      "found val set two\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def is_hol_weekend(row):\n",
    "    if row['weekday'] == 6 or row['weekday'] == 7:\n",
    "        return 1\n",
    "    if row['isHoliday'] == 1:\n",
    "        return 1\n",
    "    if row['hour'] > 17 or row['hour'] < 9:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def generate_dataframe(dataframe):\n",
    "    dataframe = convert_weekdays(dataframe)\n",
    "    \n",
    "    del dataframe[\"month\"]\n",
    "    del dataframe[\"year\"]\n",
    "    del dataframe[\"station\"]\n",
    "    del dataframe[\"precipitation.l.m2\"]\n",
    "    \n",
    "    del dataframe[\"latitude\"]\n",
    "    del dataframe[\"longitude\"]\n",
    "    \n",
    "    \n",
    "    default_columns = list(dataframe.columns)\n",
    "    \n",
    "    dataframe['isOff'] = dataframe.apply(is_hol_weekend,axis=1)\n",
    "    \n",
    "    default_columns = [\"isOff\"] + default_columns\n",
    "    \n",
    "    dataframe = dataframe[default_columns]\n",
    "    \n",
    "    del dataframe['isHoliday']\n",
    "    \n",
    "    \n",
    "    columns = list(dataframe.columns[-6:])\n",
    "    \n",
    "    if \"bikes\" in columns:\n",
    "        pass\n",
    "    else:\n",
    "        columns = columns[1:]\n",
    "    \n",
    "    num_docks = dataframe[\"numDocks\"]\n",
    "    \n",
    "    del dataframe[\"numDocks\"]\n",
    "    \n",
    "    return dataframe, num_docks\n",
    "\n",
    "def prepare_dataframe(dataframe):\n",
    "    \n",
    "    # # deleting unneeded columns\n",
    "    del dataframe[\"month\"]\n",
    "    del dataframe[\"year\"]\n",
    "    del dataframe[\"station\"]\n",
    "    del dataframe[\"precipitation.l.m2\"]\n",
    "    \n",
    "    del dataframe[\"latitude\"]\n",
    "    del dataframe[\"longitude\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    default_columns = list(dataframe.columns)\n",
    "    dataframe['isOff'] = dataframe.apply(is_hol_weekend,axis=1)\n",
    "\n",
    "    default_columns = [\"isOff\"] + default_columns\n",
    "    default_columns.remove('weekday')\n",
    "    \n",
    "    \n",
    "    dataframe = dataframe[default_columns]\n",
    "\n",
    "    del dataframe['isHoliday']\n",
    "    \n",
    "    \n",
    "    columns = list(dataframe.columns[-6:])\n",
    "    \n",
    "    if \"bikes\" in columns:\n",
    "        pass\n",
    "    else:\n",
    "        columns = columns[1:]\n",
    "\n",
    "    num_docks = dataframe[\"numDocks\"]\n",
    "    \n",
    "    dataframe[\"numDocks\"]\n",
    "\n",
    "    return dataframe, num_docks\n",
    "\n",
    "\n",
    "trains = []\n",
    "vals = []\n",
    "\n",
    "train_docks_list = []\n",
    "val_docks_list = []\n",
    "\n",
    "scalers = []\n",
    "count = 0\n",
    "for i, path in enumerate(Path('./Train/Train').rglob('*.csv')):\n",
    "    count += 1\n",
    "\n",
    "val_inds = np.random.randint(0, count - 1, 2)\n",
    "print(f'Stations kept as holdout: {200 + val_inds}')\n",
    "val_inds = list(val_inds)\n",
    "\n",
    "\n",
    "for i, path in enumerate(Path('./Train/Train').rglob('*.csv')):\n",
    "    tmp = pd.read_csv(path)\n",
    "\n",
    "    tmp = tmp.dropna(axis='rows')\n",
    "\n",
    "\n",
    "    \n",
    "    if i  not in  val_inds:\n",
    "        train, val = train_test_split(tmp, test_size=0.02)\n",
    "\n",
    "        train, train_docks = prepare_dataframe(train)\n",
    "        val, val_docks = prepare_dataframe(val)\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        \n",
    "        train[train.columns[:-1]] = scaler.fit_transform(train[train.columns[:-1]])\n",
    "        val[val.columns[:-1]] = scaler.transform(val[val.columns[:-1]])\n",
    "\n",
    "        trains.append(train)\n",
    "        vals.append(val)\n",
    "\n",
    "        train_docks_list.append(train_docks)\n",
    "        val_docks_list.append(val_docks)\n",
    "\n",
    "        scalers.append(scaler)\n",
    "        \n",
    "        del tmp\n",
    "    elif i == val_inds[0]:\n",
    "        val_set = tmp.copy()\n",
    "\n",
    "\n",
    "        val_set, val_set_docks = prepare_dataframe(val_set)\n",
    "    else:\n",
    "        print('found val set two')\n",
    "        val_set_two = tmp.copy()\n",
    "\n",
    "\n",
    "        val_set_two, val_set_docks_two = prepare_dataframe(val_set_two)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c3789",
   "metadata": {},
   "source": [
    "## Fit a model for each station on its training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f603dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 73/73 [00:24<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted in 24.534467935562134s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from tqdm import tqdm\n",
    "start = time()\n",
    "print(\"initialised\")\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in tqdm(range(len(trains))):\n",
    "    #forest_boost = AdaBoostRegressor(n_estimators=400, random_state=0, learning_rate = 0.5)\n",
    "    forest_boost = RandomForestRegressor(n_estimators= 200, max_depth= 9)\n",
    "    #forest_boost = GradientBoostingRegressor(n_estimators= 150, max_depth= 3, learning_rate= 0.1, loss=\"squared_error\")#\n",
    "    forest_boost.fit(trains[i].iloc[:,:-1].to_numpy(), trains[i][\"bikes\"].to_numpy())\n",
    "    \n",
    "    models.append(forest_boost)\n",
    "print(f'fitted in {time() - start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce321de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 73/73 [00:01<00:00, 67.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-rounded ensemble error: 1.895581889817394\n",
      "Rounded ensemble error: 1.8630136986301373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = []\n",
    "rounded_errors = []\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "\n",
    "for i in tqdm(range(len(vals))):\n",
    "    errors.append(score_abs_error(models[i], vals[i], val_docks_list[i]))\n",
    "    rounded_errors.append(score_abs_error(models[i], vals[i], val_docks_list[i], round_ = True))\n",
    "    \n",
    "    pred = list(models[i].predict(vals[i].iloc[:, :-1].to_numpy()))# * val_docks_list[i])\n",
    "    \n",
    "    y_pred = y_pred + pred\n",
    "    \n",
    "    y_gold = y_gold + list(vals[i][\"bikes\"])# * val_docks_list[i])\n",
    "    \n",
    "print(f'Non-rounded ensemble error: {np.mean(errors)}')\n",
    "print(f'Rounded ensemble error: {np.mean(rounded_errors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e610d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = np.array(errors)\n",
    "model_weights = 1/ model_weights**(2)\n",
    "model_weights = model_weights / np.sum(model_weights)\n",
    "\n",
    "\n",
    "plt.hist(model_weights, bins=30)\n",
    "plt.title(\"Model weights pre-adjustment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb0c47",
   "metadata": {},
   "source": [
    "## Measure performance on the first holdout station and adjust weights accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2727a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error pre re-tuning:  3.5971568922578627\n"
     ]
    }
   ],
   "source": [
    "def ensemble_validation_errors(models, scalers, x, y,  docks):\n",
    "    results = np.zeros(len(models))\n",
    "    \n",
    "    for i, m in enumerate(models):\n",
    "\n",
    "        x_i = scalers[i].transform(x)\n",
    "        \n",
    "        results[i] = mean_absolute_error(m.predict(x_i),y)# * docks, y*docks)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "validation_errors = ensemble_validation_errors(models, scalers, val_set.iloc[:, :-1], val_set[\"bikes\"], val_set_docks)\n",
    "\n",
    "print(f'Validation error pre re-tuning:  {np.mean(validation_errors)}')\n",
    "\n",
    "model_weights = model_weights / validation_errors**2\n",
    "model_weights = model_weights / np.sum(model_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ff474",
   "metadata": {},
   "source": [
    "## Measure performance on second holdout station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ce760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error on second holdout station: 2.177834013880668\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(models, scalers, model_weights, x):\n",
    "    results = np.zeros(x.shape[0])\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "\n",
    "        x_i = scalers[i].transform(x)\n",
    "        \n",
    "        results = results + m.predict(x_i) * model_weights[i]\n",
    "\n",
    "    return results\n",
    "\n",
    "y_pred = ensemble_predict(models, scalers, model_weights, val_set_two.iloc[:,:-1])\n",
    "\n",
    "val_gold_two = val_set_two[\"bikes\"].to_numpy()\n",
    "\n",
    "print(f'\\nError on second holdout station: {mean_absolute_error(val_gold_two, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f06358",
   "metadata": {},
   "source": [
    "## Use ensemble to predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8729bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "ids = test[\"Id\"]\n",
    "\n",
    "del test[\"Id\"]\n",
    "\n",
    "test, test_docks = prepare_dataframe(test)\n",
    "\n",
    "y_pred = np.around(ensemble_predict(models, scalers, model_weights, test)).astype(np.int32)\n",
    "\n",
    "\n",
    "sub_df = pd.DataFrame(data=y_pred, index = ids, columns = [\"bikes\"])\n",
    "\n",
    "sub_df.index.name = 'Id'\n",
    "\n",
    "sub_df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f506f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
