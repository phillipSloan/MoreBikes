{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c941f519",
   "metadata": {},
   "source": [
    "# Notebook for subtask-A of phase one\n",
    "\n",
    "## Fitting a model to each individual station\n",
    "\n",
    "Here we construct an ensemble, with the use case of predicting for new stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73b88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb9c42",
   "metadata": {},
   "source": [
    "# Define some functions\n",
    "\n",
    "- replace_nan fills NaN values with column means. We don't use it but it was useful for exploratory analysis\n",
    "- show_nans is also for exploration\n",
    "- convert_weekdays moves weekday strings into integers from one to seven\n",
    "- score_abs_error takes a model with SKLEARN syntax and used it to predict the number of bikes based on input data, then return the mean absolute error. round_ specifies whether output should be rounded to integers.\n",
    "- reasonable_predictions is a bit redundant, taking a model and data and predicting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361f428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(df):\n",
    "    # get a list of all the columns containing NaN\n",
    "    nan_cols = df[df.columns[df.isnull().any()]].columns\n",
    "    nan_cols = nan_cols.drop('bikes')\n",
    "    # compute and fill each NaN with the columns mean\n",
    "    df[nan_cols] = df[nan_cols].fillna(value=df[nan_cols].mean())\n",
    "\n",
    "    \n",
    "def show_nans(df):\n",
    "    print(np.unique(df['station']))\n",
    "    print(df.shape[0] - df.dropna().shape[0])\n",
    "#     print(df[df.columns[df.isnull().any()]].columns)\n",
    "    print(df.isnull().any())\n",
    "    print()\n",
    "    \n",
    "\n",
    "# converting weekdays into integers [1-7]\n",
    "def convert_weekdays(df):\n",
    "    df = df.replace(\n",
    "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    [1, 2, 3, 4, 5, 6, 7])\n",
    "    return df\n",
    "    \n",
    "def score_abs_error(model, data, num_docks, round_ = False):\n",
    "    if round_ == True:\n",
    "        y_pred = np.around(  model.predict(data.iloc[:,:-1].to_numpy()))# * num_docks  )\n",
    "    else:\n",
    "        y_pred = model.predict(data.iloc[:,:-1].to_numpy())# * num_docks\n",
    "    y_gold = data[\"bikes\"].to_numpy()# * num_docks\n",
    "    \n",
    "    return mean_absolute_error(y_gold, y_pred)\n",
    "\n",
    "def reasonable_predictions(model, data):\n",
    "    y_pred = model.predict(data.to_numpy())\n",
    "    \n",
    "    y_pred = np.around(y_pred)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb0834",
   "metadata": {},
   "source": [
    "The next cell has functions to remove unwanted features, add our new isOff feature. \n",
    "\n",
    "It reads all the training files and builds collections of training sets, validation sets, and scalers for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e71e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 51]\n",
      "found val set two\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def is_hol_weekend(row):\n",
    "    if row['weekday'] == 6 or row['weekday'] == 7:\n",
    "        return 1\n",
    "    if row['isHoliday'] == 1:\n",
    "        return 1\n",
    "    if row['hour'] > 17 or row['hour'] < 9:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def generate_dataframe(dataframe):\n",
    "    dataframe = convert_weekdays(dataframe)\n",
    "    \n",
    "    del dataframe[\"month\"]\n",
    "    del dataframe[\"year\"]\n",
    "    del dataframe[\"station\"]\n",
    "    del dataframe[\"precipitation.l.m2\"]\n",
    "    \n",
    "    del dataframe[\"latitude\"]\n",
    "    del dataframe[\"longitude\"]\n",
    "    \n",
    "    \n",
    "    default_columns = list(dataframe.columns)\n",
    "    \n",
    "    dataframe['isOff'] = dataframe.apply(is_hol_weekend,axis=1)\n",
    "    \n",
    "    default_columns = [\"isOff\"] + default_columns\n",
    "    \n",
    "    dataframe = dataframe[default_columns]\n",
    "    \n",
    "    print(dataframe.columns)\n",
    "    \n",
    "    del dataframe['isHoliday']\n",
    "    \n",
    "    \n",
    "    columns = list(dataframe.columns[-6:])\n",
    "    \n",
    "    if \"bikes\" in columns:\n",
    "        pass\n",
    "    else:\n",
    "        columns = columns[1:]\n",
    "    \n",
    "    num_docks = dataframe[\"numDocks\"]\n",
    "    \n",
    "    del dataframe[\"numDocks\"]\n",
    "    \n",
    "    return dataframe, num_docks\n",
    "\n",
    "def prepare_dataframe(dataframe):\n",
    "    \n",
    "    # # deleting unneeded columns\n",
    "    del dataframe[\"month\"]\n",
    "    del dataframe[\"year\"]\n",
    "    del dataframe[\"station\"]\n",
    "    del dataframe[\"precipitation.l.m2\"]\n",
    "    \n",
    "    del dataframe[\"latitude\"]\n",
    "    del dataframe[\"longitude\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    default_columns = list(dataframe.columns)\n",
    "    dataframe['isOff'] = dataframe.apply(is_hol_weekend,axis=1)\n",
    "\n",
    "    default_columns = [\"isOff\"] + default_columns\n",
    "    default_columns.remove('weekday')\n",
    "    \n",
    "    \n",
    "    dataframe = dataframe[default_columns]\n",
    "\n",
    "    del dataframe['isHoliday']\n",
    "    \n",
    "    \n",
    "    columns = list(dataframe.columns[-6:])\n",
    "    \n",
    "    if \"bikes\" in columns:\n",
    "        pass\n",
    "    else:\n",
    "        columns = columns[1:]\n",
    "\n",
    "    num_docks = dataframe[\"numDocks\"]\n",
    "    \n",
    "    dataframe[\"numDocks\"]\n",
    "\n",
    "    return dataframe, num_docks\n",
    "\n",
    "\n",
    "trains = []\n",
    "vals = []\n",
    "\n",
    "train_docks_list = []\n",
    "val_docks_list = []\n",
    "\n",
    "scalers = []\n",
    "count = 0\n",
    "for i, path in enumerate(Path('./Train/Train').rglob('*.csv')):\n",
    "    count += 1\n",
    "\n",
    "val_inds = list(np.random.randint(0, count - 1, 2))\n",
    "print(f'Stations kept as holdout: {200 + val_inds}')\n",
    "val_inds = list(val_inds)\n",
    "\n",
    "\n",
    "for i, path in enumerate(Path('./Train/Train').rglob('*.csv')):\n",
    "    tmp = pd.read_csv(path)\n",
    "\n",
    "    tmp = tmp.dropna(axis='rows')\n",
    "\n",
    "\n",
    "    \n",
    "    if i  not in  val_inds:\n",
    "        train, val = train_test_split(tmp, test_size=0.02)\n",
    "\n",
    "        train, train_docks = prepare_dataframe(train)\n",
    "        val, val_docks = prepare_dataframe(val)\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        \n",
    "        train[train.columns[:-1]] = scaler.fit_transform(train[train.columns[:-1]])\n",
    "        val[val.columns[:-1]] = scaler.transform(val[val.columns[:-1]])\n",
    "\n",
    "        trains.append(train)\n",
    "        vals.append(val)\n",
    "\n",
    "        train_docks_list.append(train_docks)\n",
    "        val_docks_list.append(val_docks)\n",
    "\n",
    "        scalers.append(scaler)\n",
    "        \n",
    "        del tmp\n",
    "    elif i == val_inds[0]:\n",
    "        val_set = tmp.copy()\n",
    "\n",
    "\n",
    "        val_set, val_set_docks = prepare_dataframe(val_set)\n",
    "    else:\n",
    "        print('found val set two')\n",
    "        val_set_two = tmp.copy()\n",
    "\n",
    "\n",
    "        val_set_two, val_set_docks_two = prepare_dataframe(val_set_two)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de7413",
   "metadata": {},
   "source": [
    "## Fit a model for each station on its training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc560ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 73/73 [00:24<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted in 24.214744091033936s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from tqdm import tqdm\n",
    "start = time()\n",
    "print(\"initialised\")\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in tqdm(range(len(trains))):\n",
    "    #forest_boost = AdaBoostRegressor(n_estimators=400, random_state=0, learning_rate = 0.5)\n",
    "    forest_boost = RandomForestRegressor(n_estimators= 200, max_depth= 9)\n",
    "    #forest_boost = GradientBoostingRegressor(n_estimators= 150, max_depth= 3, learning_rate= 0.1, loss=\"squared_error\")#\n",
    "    forest_boost.fit(trains[i].iloc[:,:-1].to_numpy(), trains[i][\"bikes\"].to_numpy())\n",
    "    \n",
    "    models.append(forest_boost)\n",
    "print(f'fitted in {time() - start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f445e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 73/73 [00:01<00:00, 66.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-rounded ensemble error: 1.7763721951123324\n",
      "Rounded ensemble error: 1.7636986301369864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = []\n",
    "rounded_errors = []\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "\n",
    "for i in tqdm(range(len(vals))):\n",
    "    errors.append(score_abs_error(models[i], vals[i], val_docks_list[i]))\n",
    "    rounded_errors.append(score_abs_error(models[i], vals[i], val_docks_list[i], round_ = True))\n",
    "    \n",
    "    pred = list(models[i].predict(vals[i].iloc[:, :-1].to_numpy()))# * val_docks_list[i])\n",
    "    \n",
    "    y_pred = y_pred + pred\n",
    "    \n",
    "    y_gold = y_gold + list(vals[i][\"bikes\"])# * val_docks_list[i])\n",
    "    \n",
    "print(f'Non-rounded ensemble error: {np.mean(errors)}')\n",
    "print(f'Rounded ensemble error: {np.mean(rounded_errors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8280001d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = np.array(errors)\n",
    "model_weights = 1/ model_weights**(2)\n",
    "model_weights = model_weights / np.sum(model_weights)\n",
    "\n",
    "\n",
    "plt.hist(model_weights, bins=30)\n",
    "plt.title(\"Model weights pre-adjustment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be92492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error pre re-tuning:  4.999500925746927\n"
     ]
    }
   ],
   "source": [
    "def ensemble_validation_errors(models, scalers, x, y,  docks):\n",
    "    results = np.zeros(len(models))\n",
    "    \n",
    "    for i, m in enumerate(models):\n",
    "\n",
    "        x_i = scalers[i].transform(x)\n",
    "        \n",
    "        results[i] = mean_absolute_error(m.predict(x_i),y)# * docks, y*docks)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "validation_errors = ensemble_validation_errors(models, scalers, val_set.iloc[:, :-1], val_set[\"bikes\"], val_set_docks)\n",
    "\n",
    "print(f'Validation error pre re-tuning:  {np.mean(validation_errors)}')\n",
    "\n",
    "model_weights = model_weights / validation_errors**2\n",
    "model_weights = model_weights / np.sum(model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd12e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error on second holdout station: 2.073630617529239\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(models, scalers, model_weights, x):\n",
    "    results = np.zeros(x.shape[0])\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "\n",
    "        x_i = scalers[i].transform(x)\n",
    "        \n",
    "        results = results + m.predict(x_i) * model_weights[i]\n",
    "\n",
    "    return results\n",
    "\n",
    "y_pred = ensemble_predict(models, scalers, model_weights, val_set_two.iloc[:,:-1]) #* val_set_docks_two\n",
    "\n",
    "val_gold_two = val_set_two[\"bikes\"].to_numpy()# * val_set_docks_two\n",
    "\n",
    "print(f'\\nError on second holdout station: {mean_absolute_error(val_gold_two, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e191ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "ids = test[\"Id\"]\n",
    "\n",
    "del test[\"Id\"]\n",
    "\n",
    "test, test_docks = prepare_dataframe(test)\n",
    "\n",
    "y_pred = np.around(ensemble_predict(models, scalers, model_weights, test)).astype(np.int32)\n",
    "\n",
    "\n",
    "sub_df = pd.DataFrame(data=y_pred, index = ids, columns = [\"bikes\"])\n",
    "\n",
    "sub_df.index.name = 'Id'\n",
    "\n",
    "sub_df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc21464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
